### PERGUNTA

Descreva seus próprios critérios para que um sistema computacional seja considerado "inteligente".

#### RESPOSTA

O **Teste de Turing** não prova a possibilidade de uma *Inteligência Artificial **Forte***, mas continuo com o Teste de Turing como critério para a *Inteligência Artificial **Fraca***.

Um critério demasiado abstrato para uma máquina pensar seria **ter uma consciência**. Imita-la não é suficiente para a IAF, como defende Searle, nas palavras de [José Evangelista](https://www20.opovo.com.br/app/colunas/aquitemciencia/2015/07/04/noticiaaquitemciencia,3464099/a-sala-chinesa-de-john-searle.shtml):
> « Um computador usual funciona em série, manipulando bits de forma sequencial. Mas, já existem computadores com processamento paralelo e uma arquitetura que tenta reproduzir a estrutura de um cérebro, com neurônios e sinapses convenientemente plásticas a ponto de serem modificadas à medida que a máquina vai recebendo novas informações. Em outras palavras, esse tipo de computador que usa uma rede neural artificial é capaz de “aprender” enquanto manipula os dados que recebe. Se um computador desse tipo for usado em uma Sala Chinesa de Searle, sua troca de informação com o humano chinês seria cada vez mais elaborada e perfeita. Nesse caso, poderíamos dizer que essa máquina acabaria “entendendo” chinês?
>
> Searle protesta dizendo que esse exemplo contradiz os defensores da IA “forte”, pois depende não apenas do programa (o “software”). Assim mesmo, segundo ele, essa máquina nunca entenderia o chinês, apenas simularia esse entendimento. Um computador e seu programa, por mais sofisticados, apenas processam informações – e processamento de informação não equivale a pensar.
>
> Na verdade, diz Searle, o pensamento consciente deriva, necessariamente, de processos físico-químicos que não são reproduzidos em nenhum computador. A mente, segundo ele, não pode ser dissociada do cérebro. Aliás, não apenas do cérebro, mas de todo o organismo que interage com o cérebro trocando informações enquanto troca moléculas biológicas.
>
> **A ideia, usada por autores de ficção científica, de que seria possível “exportar” uma mente de um cérebro para uma máquina externa, é inteiramente equivocada, segundo o filósofo americano**. »

Sendo mais especifico, ter uma consciência seria o sinônimo de ser uma alma-e-um-corpo, como defende o [Tomismo](http://www.aquinate.com.br/textos/a-filosofia-contemporanea-da-mente-em-perspectiva-tomista/):
> « A forma substancial do ente vivo é a sua alma. A alma sempre determina um modo de vida específico, i.e., conforme à espécie, constituindo o ente singular por sua união a uma quantidade delimitada de matéria (materia signata quantitate). A ideia de individuação pela matéria não deve conduzir à conclusão de que a alma seja, essencialmente, uma forma separada (à qual ocorre, como se acidentalmente, a união ao corpo – i.e., à matéria informada). » (p. 22)

Mas fora isto, há um critério mais objetivo proposto por Eric Matthews:
> Se tivéssemos uma forma mais eficaz de decidir se os computadores poderiam realmente pensar como as pessoas o fazem, então deveríamos incluir questões para as quais não existe uma única resposta correta. Os exemplos poderiam ser, ‘Você tem medo da morte?’, ‘A política sobre aposentadoria do grupo A é melhor do que aquela do grupo B?’, ‘O aborto é moralmente errado?’, ‘Os telefones celulares são coisas boas?’, e assim por diante. O teste para verificar se o pensamento está ocorrendo não estaria dentro da resposta oferecida, mas se, sim ou não, as razões são dadas para uma resposta em particular. Essa troca de pergunta e resposta claramente não poderia ser trabalhada com os procedimentos utilizados por Searle no quarto chinês, pois não existiriam regras para dizer qual conjunto de símbolos seria a resposta adequada em tal caso.
>
> **Mente (Conceitos-Chave em Filosofia)**, Eric Matthews, p. 98.

No entanto, como o o próprio autor também salienta:
> No entanto, com perguntas mais diretas para as quais podem ser dadas respostas ‘certas’ ou ‘erradas’, a compreensão também é necessária para o exercício genuíno da inteligência. Posso ‘perguntar’ à minha calculadora de bolso quanto é 789 multiplicado por 456 e receber a ‘resposta’ de 359.784. A multiplicação é governada por regras muito rigorosas nas quais a calculadora pode ser programada para executar: se ela estiver funcionando bem, a ‘resposta’ que é ‘oferecida’ será garantida como correta. No entanto, literalmente, a calculadora não fez nenhum cálculo: um cálculo legítimo envolve a compreensão das regras e aplicá-las de acordo. Por esse motivo, um teste que se baseasse inteiramente em respostas não nos possibilitaria decidir se computadores (programados) podem pensar. Possuir uma ‘mente’ não é uma questão de ser capaz de oferecer respostas corretas a perguntas (mesmo que seja possível falar de respostas ‘corretas’), mas uma questão de possuir algum entendimento sobre o que está se dizendo.
>
> **Mente (Conceitos-Chave em Filosofia)**, Eric Matthews, p. 98.
